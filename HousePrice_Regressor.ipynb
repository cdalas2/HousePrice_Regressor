{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uBbRybjU-xjE"
   },
   "source": [
    "# **Random Forest Regression on the California Housing dataset**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "48r-OKiExtSw"
   },
   "source": [
    "**Importing all the required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9kE4RyoD-4-z"
   },
   "outputs": [],
   "source": [
    "#The sklearn.ensemble module includes the RandomForest algorithm.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Libraries for calculating evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T8NUIU9Z_YE4"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YduDpy8BsWD",
    "outputId": "16569e0e-a5b5-4ce2-b325-7f888a720994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n",
      "(20640, 8)\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "        0     1         2         3       4         5      6       7\n",
      "0  8.3252  41.0  6.984127  1.023810   322.0  2.555556  37.88 -122.23\n",
      "1  8.3014  21.0  6.238137  0.971880  2401.0  2.109842  37.86 -122.22\n",
      "2  7.2574  52.0  8.288136  1.073446   496.0  2.802260  37.85 -122.24\n",
      "3  5.6431  52.0  5.817352  1.073059   558.0  2.547945  37.85 -122.25\n",
      "4  3.8462  52.0  6.281853  1.081081   565.0  2.181467  37.85 -122.25\n",
      "       0\n",
      "0  4.526\n",
      "1  3.585\n",
      "2  3.521\n",
      "3  3.413\n",
      "4  3.422\n"
     ]
    }
   ],
   "source": [
    "print(housing_data.keys())\n",
    "print(housing_data.data.shape)\n",
    "print(housing_data.DESCR)\n",
    "\n",
    "print(pd.DataFrame(housing_data.data)[:5])\n",
    "print(pd.DataFrame(housing_data.target)[:5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5sspyXSmy17q"
   },
   "source": [
    "**Split the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlcuTTiTy9Tk",
    "outputId": "2b88a687-552d-418d-ae08-e9a440d75699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data=  14448  Samples\n",
      "Size of testing data=  6192  Samples\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.common import random_state\n",
    "X = housing_data.data\n",
    "y = housing_data.target\n",
    "\n",
    "\n",
    "##### Use numpy arrays ######\n",
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "assert X_train.shape == (14448, 8)\n",
    "assert y_train.shape == (14448,)\n",
    "assert X_test.shape == (6192, 8)\n",
    "assert y_test.shape == (6192,)\n",
    "\n",
    "print(\"Size of training data= \", X_train.shape[0],\" Samples\")\n",
    "print(\"Size of testing data= \", X_test.shape[0],\" Samples\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "z3WOEAy8zjln"
   },
   "source": [
    "**Fit model to training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "pLKCjKwJzofY",
    "outputId": "e87ece31-4442-490f-d56f-e433506e4b18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xvTNzrcr0j4x"
   },
   "source": [
    "**Try Predicting Values**\n",
    "Change values of features to see changes in the predicted value of house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rIm-v6ZH0Ju",
    "outputId": "e85edbe4-8bf4-4c55-d329-4932cbad1a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Value Prediction= $ 443904.09000000043\n"
     ]
    }
   ],
   "source": [
    "# this is an example test case depicting how the prediction is done on a test data point.\n",
    "\n",
    "val1 = 8.3252\n",
    "val2 = 41.0\n",
    "val3 = 6.984127\n",
    "val4 = 1.023810\n",
    "val5 = 322.0\n",
    "val6 = 2.555556\n",
    "val7 = 37.88\n",
    "val8 = -122.23\n",
    "\n",
    "row = [[val1, val2, val3, val4, val5, val6, val7, val8]]\n",
    "\n",
    "# make a single prediction\n",
    "yhat = model.predict(row)\n",
    "\n",
    "print('House Value Prediction= $',yhat[0]*100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RfzVPn0x437S"
   },
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oHbnwEyt48Mr"
   },
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qqGiMHYC5FFu"
   },
   "source": [
    "**Visualize the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sv-idAUX5Il-",
    "outputId": "a254ef08-cac2-45ef-ebbb-68b6b424bf67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error =  0.27443212441750414\n"
     ]
    }
   ],
   "source": [
    "mse = None\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error = \",mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jKHA6-2_KTDh"
   },
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-PZtUfovUgiQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "YHFVGQB1Uf_n",
    "outputId": "a7b53141-cac5-4802-9fed-058a83534733"
   },
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "     'n_estimators': [10, 50, 100, 150, 200], \n",
    "     'max_features': [4, 5, 6, 7, 8], \n",
    "     'max_depth': [6, 7, 8, 9, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "#Use Random Forests\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform the grid search on the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKupJ2WmK180",
    "outputId": "909e827f-fd43-40c9-e41b-4202adad87ac"
   },
   "outputs": [],
   "source": [
    "# Display the best parameter combination\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error after hyperparameter tuning = \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eE45RFvZjwg9"
   },
   "source": [
    "**Retrain the model using only the top 5 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoO1A39jjuaf",
    "outputId": "28c423ab-57d6-4fc2-f538-da63144d6fc6"
   },
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order and select top 5\n",
    "top5_feature_indices = np.argsort(feature_importances)[::-1][:5]\n",
    "\n",
    "#print top 5 import features\n",
    "print(\"Top 5 important features:\")\n",
    "for i in top5_feature_indices:\n",
    "    print(housing_data.feature_names[i])\n",
    "\n",
    "# Retrain the model using only the top 5 features\n",
    "X_train_top_features = X_train[:, top5_feature_indices]\n",
    "X_test_top_features = X_test[:, top5_feature_indices]\n",
    "\n",
    "model.fit(X_train_top_features, y_train)\n",
    "y_pred = model.predict(X_test_top_features)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error after feature selection = \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mve7Cd-al-s0"
   },
   "source": [
    "**Plot Learning Curve and Calculate Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xZskX09Hl8g_",
    "outputId": "f287cf7f-4bc2-4f94-d500-7ea3d4ffed35"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "# Get learning curves\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.plot(train_sizes, train_mean, label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aciYVvHl6SXc"
   },
   "source": [
    "We will take a closer look at some of the hyperparameters we should consider tuning for the random forest ensemble and their effect on model performance.\n",
    "\n",
    "We select the hyperparameters that give us the lowest error rate or Mean Square Error in this case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MORy4fvn6tLr"
   },
   "source": [
    "First we define a function to evaluate a model using the mean square error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZMltehuec4q"
   },
   "outputs": [],
   "source": [
    "def find_mse(model, X, y):\n",
    "\n",
    "  yhat = model.predict(X)\n",
    "  mse = mean_squared_error(y,yhat) \n",
    "\n",
    "  return mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U53kHMzd6-7l"
   },
   "source": [
    "Next we define a function to test out various models and plot how the Mean Square Error evolves with respect to the hyperparameter in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttit1Xm4eqeP"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def plot_tuning(models_dict,X_train,X_test,y_train,y_test):\n",
    "\n",
    "  results, names = list(), list()\n",
    "\n",
    "  for name, model in models_dict.items():\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = find_mse(model, X_test, y_test)\n",
    "  \n",
    "    results.append(mse)\n",
    "    names.append(name)\n",
    "    print(\"Hyperparameter= \",name,\"; MSE = \",mse)\n",
    "\n",
    "\n",
    "    n = [float(i) for i in names]\n",
    "\n",
    "  pyplot.plot(n,results)\n",
    "  pyplot.ylabel('Mean Square Error')\n",
    "  pyplot.xlabel('Hyperparameter')\n",
    "  pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-AbjOvTDeCGR"
   },
   "source": [
    "**Hyperparameter:** max_samples.\n",
    "\n",
    "The **max_samples** argument can be set to a float between 0 and 1 to control the percentage of the size of the training dataset to make the sample used to train each decision tree. **None** means that the entire training set will be used to train each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcEEhuLEYpZ1"
   },
   "outputs": [],
   "source": [
    "#Store various models into a dictionary of models\n",
    "models_dict = dict()\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "  # set max_samples=None to use 100%\n",
    "  key = round(i,2)\n",
    "  if i == 1.0:\n",
    "    i = None\n",
    "  models_dict[key] = RandomForestRegressor(max_samples=i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "3UkIwr82m4wF",
    "outputId": "59dd13ed-00e4-48b2-d140-16eb367befbe"
   },
   "outputs": [],
   "source": [
    "#Plot the MSE for all models in the dictionary\n",
    "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U1TOelFJ9jXx"
   },
   "source": [
    "**Hyperparameter:** max_features.\n",
    "\n",
    "The number of features that is randomly sampled for each split point is perhaps the most important feature to configure for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1TOiDTDgL7h"
   },
   "outputs": [],
   "source": [
    "#Store various models into a dictionary of models\n",
    "models_dict = dict()\n",
    "\n",
    "for i in range(1,8):\n",
    "  models_dict[str(i)] = RandomForestRegressor(max_features=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "LSgMQgIfne3Q",
    "outputId": "8ace0015-3c8d-4aab-be48-70ce6a75ed75"
   },
   "outputs": [],
   "source": [
    "#Plot the MSE for all models in the dictionary\n",
    "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2FEQHe7Y-Khh"
   },
   "source": [
    "**Hyperparameter:** n_estimators.\n",
    "\n",
    "Typically, the number of trees is increased until the model performance stabilizes. Intuition might suggest that more trees will lead to overfitting, although this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTblvr9xnh_0"
   },
   "outputs": [],
   "source": [
    "#Store various models into a dictionary of models\n",
    "models_dict = dict()\n",
    "\n",
    "n_trees = [10, 50, 100, 500, 1000]\n",
    "for n in n_trees:\n",
    "    models_dict[str(n)] = RandomForestRegressor(n_estimators=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "FRLUXSYXoGeE",
    "outputId": "1d0e2852-492d-4be8-dd81-3fd0781fa070"
   },
   "outputs": [],
   "source": [
    "#Plot the MSE for all models in the dictionary\n",
    "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
